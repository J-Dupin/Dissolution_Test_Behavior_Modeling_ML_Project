{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a294d4b",
   "metadata": {},
   "source": [
    "# Dissolution Stability Machine Learning Project Using a Gaussian Mixture Model\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This project aims to analyze dissolution test data using GMMs.\n",
    "\n",
    "In pharmaceutical development and manufacturing, dissolution testing data allows one to predict how quickly and completely a drug will dissolve in a patient's body.\n",
    "\n",
    "Dissolution methods, however, may vary greatly (e.g., different media, apparatus, agitation speeds, sampling times), and real test results are prone to showing heterogeneity (e.g., some tablets dissolve quickly, others slowly). This project therefore aims to address this problem by building a computational workflow which is able to complete the following:\n",
    "1) Translate Food and Drug Administration (FDA) method metadata into clearly structured features;\n",
    "2) Use kinetic models to generate realistic synthetic dissolution profiles;\n",
    "3) Apply a selection of Gaussian Mixture Models (GMMs) to cluster these profiles into meaningful subgroups (e.g., “fast,” “medium,” “slow”); and\n",
    "4) Provide a framework that can be applied to real experimental data to detect unexpected subpopulations or anomalies.\n",
    "\n",
    "This project hopes to add value within the pharmaceutical and biotechnology sector as it could demonstrate how data analysis, machine learning, and statistical modeling can benefit method development, risk assessment, and QC analysis.\n",
    "\n",
    "The program will intake as inputs the FDA's Dissolution methods database metadata (which includes a drug's dosage form (tablet, capsule, etc.), its apparatus type (basket, paddle, cylinder, etc.), its agitation speed (rpm), its medium composition (e.g., water, HCl, buffer with surfactant), its medium volume (e.g., 500 mL, 900 mL), and its sampling times (e.g., 5, 10, 20, 30, 60 min)) and a selection of synthetic dissolution profiles (simulated from the metadata). For instance, a first-order or Weibull kinetic model may be used to generate curves plotting the percentage of the drug dissolved over time. Parameters can parhaps be linked to method settings (e.g., higher RPM values could lead to faster rate constants).\n",
    "\n",
    "The program aims to yield several outputs. Firstly, it will cluster dissolution profiles illustrating subgroups of methods/curves labeled as “fast,” “medium,” or “slow” dissolvers. It will also produce informative visualizations such as plots of dissolution curves by cluster and 2D/3D projections of feature space color coded by cluster group. The program will provide cluster descriptors––statistical summaries of what differentiates each subgroup (e.g., Cluster 0 uses low RPM, short times result in fast release). Finally, it will generate probabilistic insights drawn from the data. By using GMMs, the likelihood that a new profile belongs to each subgroup will be known which is crucial for uncertainty handling and model evaluation.\n",
    "\n",
    "It is hoped that this project would become useful in real-world pharmaceutical and/or biotechnology contexts during several stages, including in Research and Development (R&D), in Process and Method Development, in Manufacturing and Quality Assurance, and in Regulatory and Reporting Operations.\n",
    "\n",
    "This program may be useful during formulation development as it could be capable of identifying whether a drug batch behaves consistently or splits into sub-populations (e.g., two different release rates). This could help scientists detect potential formulation robustness issues early. It may also be potentially used to compare FDA-recommended methods across drugs and to find natural clusters of dissolution conditions (e.g., methods suited for immediate vs. extended-release). During operation and quality checking, the most performant model might be applied to real batch data. If some tablets cluster into a “slow dissolving” subgroup unexpectedly, this could flag a potential manufacturing deviation which should be addressed. Furthermore, it might be able to provide a systematic way to justify why certain dissolution conditions (RPM, media, times) are chosen. Hence, this program could add a data-driven layer on top of traditional method validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb527693",
   "metadata": {},
   "source": [
    "## Analyzing Dissolution Test Data with Gaussian Mixture Models\n",
    "\n",
    "**Goal:**  \n",
    "Use FDA Dissolution Methods metadata + synthetic dissolution profiles to identify clusters of dissolution behaviors (\"fast,\" \"medium,\" \"slow\").  \n",
    "\n",
    "**Steps:**  \n",
    "1. Feature Engineering from FDA database  \n",
    "2. Synthetic Profile Generation using kinetic models  \n",
    "3. GMM clustering and visualization  \n",
    "4. Interpretation & discussion of pharma relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76719834",
   "metadata": {},
   "source": [
    "1. Problem defintion\n",
    "2. Data\n",
    "3. Evaluation\n",
    "4. Features\n",
    "5. Modelling\n",
    "6. Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f32413d",
   "metadata": {},
   "source": [
    "### 1. Notebook Setup\n",
    "\n",
    "Getting all the tools ready in the project's virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8170062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup matplotlib to plot inline (within the notebook)\n",
    "%matplotlib inline\n",
    "\n",
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# Modeling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Utility\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164d069a",
   "metadata": {},
   "source": [
    "### 2. Data Acquisition\n",
    "\n",
    "Loading the dataset (if dataset if real and available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e52f0746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1568 entries, 0 to 1567\n",
      "Data columns (total 8 columns):\n",
      " #   Column                                Non-Null Count  Dtype \n",
      "---  ------                                --------------  ----- \n",
      " 0   Drug Name                             1568 non-null   object\n",
      " 1   Dosage Form                           1568 non-null   object\n",
      " 2   USP Apparatus                         805 non-null    object\n",
      " 3   Speed (RPMs)                          800 non-null    object\n",
      " 4   Medium                                1568 non-null   object\n",
      " 5   Volume (mL)                           792 non-null    object\n",
      " 6   Recommended Sampling Times (minutes)  803 non-null    object\n",
      " 7   Date Updated                          1568 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 98.1+ KB\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Drug Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Dosage Form",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "USP Apparatus",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Speed (RPMs)",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Medium",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Volume (mL)",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Recommended Sampling Times (minutes)",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Date Updated",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "fa5d8066-1834-494c-b34c-9759c6271df7",
       "rows": [
        [
         "0",
         "Abacavir Sulfate",
         "Tablet",
         null,
         null,
         "Refer to FDA's Dissolution Guidance, 2018",
         null,
         null,
         "07/02/2020"
        ],
        [
         "1",
         "Abacavir Sulfate/Dolutegravir Sodium/Lamivudine",
         "Tablet",
         "II (Paddle)",
         "85",
         "0.01 M Phosphate Buffer with 0.5% sodium dodecyl sulfate (SDS), pH 6.8",
         "900",
         "Abacavir and lamivudine: 10, 15, 20, 30 and 45; Dolutegravir: 5,15, 25, 35 and 45.",
         "05/28/2015"
        ],
        [
         "2",
         "Abacavir Sulfate/Dolutegravir Sodium/Lamivudine",
         "Tablet (For Suspension)",
         "II (Paddle)",
         "50",
         "0.01 M Phosphate Buffer with 0.5 mM EDTA, pH 6.8",
         "500",
         "5, 10, 15, 30, 45 and 60",
         "10/06/2023"
        ],
        [
         "3",
         "Abacavir Sulfate/Lamivudine",
         "Tablet",
         "II (Paddle)",
         "75",
         "0.1 N HCl",
         "900",
         "10, 20, 30, and 45 ",
         "01/03/2007"
        ],
        [
         "4",
         "Abacavir Sulfate/Lamivudine/Zidovudine",
         "Tablet",
         "II (Paddle)",
         "75",
         "0.1 N HCl",
         "Acid Stage: 900 mL; Buffer Stage: 1000 mL",
         "5, 10, 15, 30 and 45",
         "01/03/2007"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug Name</th>\n",
       "      <th>Dosage Form</th>\n",
       "      <th>USP Apparatus</th>\n",
       "      <th>Speed (RPMs)</th>\n",
       "      <th>Medium</th>\n",
       "      <th>Volume (mL)</th>\n",
       "      <th>Recommended Sampling Times (minutes)</th>\n",
       "      <th>Date Updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abacavir Sulfate</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Refer to FDA's Dissolution Guidance, 2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07/02/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abacavir Sulfate/Dolutegravir Sodium/Lamivudine</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>II (Paddle)</td>\n",
       "      <td>85</td>\n",
       "      <td>0.01 M Phosphate Buffer with 0.5% sodium dodec...</td>\n",
       "      <td>900</td>\n",
       "      <td>Abacavir and lamivudine: 10, 15, 20, 30 and 45...</td>\n",
       "      <td>05/28/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abacavir Sulfate/Dolutegravir Sodium/Lamivudine</td>\n",
       "      <td>Tablet (For Suspension)</td>\n",
       "      <td>II (Paddle)</td>\n",
       "      <td>50</td>\n",
       "      <td>0.01 M Phosphate Buffer with 0.5 mM EDTA, pH 6.8</td>\n",
       "      <td>500</td>\n",
       "      <td>5, 10, 15, 30, 45 and 60</td>\n",
       "      <td>10/06/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abacavir Sulfate/Lamivudine</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>II (Paddle)</td>\n",
       "      <td>75</td>\n",
       "      <td>0.1 N HCl</td>\n",
       "      <td>900</td>\n",
       "      <td>10, 20, 30, and 45</td>\n",
       "      <td>01/03/2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abacavir Sulfate/Lamivudine/Zidovudine</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>II (Paddle)</td>\n",
       "      <td>75</td>\n",
       "      <td>0.1 N HCl</td>\n",
       "      <td>Acid Stage: 900 mL; Buffer Stage: 1000 mL</td>\n",
       "      <td>5, 10, 15, 30 and 45</td>\n",
       "      <td>01/03/2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Drug Name              Dosage Form  \\\n",
       "0                                 Abacavir Sulfate                   Tablet   \n",
       "1  Abacavir Sulfate/Dolutegravir Sodium/Lamivudine                   Tablet   \n",
       "2  Abacavir Sulfate/Dolutegravir Sodium/Lamivudine  Tablet (For Suspension)   \n",
       "3                      Abacavir Sulfate/Lamivudine                   Tablet   \n",
       "4           Abacavir Sulfate/Lamivudine/Zidovudine                   Tablet   \n",
       "\n",
       "  USP Apparatus Speed (RPMs)  \\\n",
       "0           NaN          NaN   \n",
       "1   II (Paddle)           85   \n",
       "2   II (Paddle)           50   \n",
       "3   II (Paddle)           75   \n",
       "4   II (Paddle)           75   \n",
       "\n",
       "                                              Medium  \\\n",
       "0          Refer to FDA's Dissolution Guidance, 2018   \n",
       "1  0.01 M Phosphate Buffer with 0.5% sodium dodec...   \n",
       "2   0.01 M Phosphate Buffer with 0.5 mM EDTA, pH 6.8   \n",
       "3                                          0.1 N HCl   \n",
       "4                                          0.1 N HCl   \n",
       "\n",
       "                                 Volume (mL)  \\\n",
       "0                                        NaN   \n",
       "1                                        900   \n",
       "2                                        500   \n",
       "3                                        900   \n",
       "4  Acid Stage: 900 mL; Buffer Stage: 1000 mL   \n",
       "\n",
       "                Recommended Sampling Times (minutes) Date Updated  \n",
       "0                                                NaN   07/02/2020  \n",
       "1  Abacavir and lamivudine: 10, 15, 20, 30 and 45...   05/28/2015  \n",
       "2                           5, 10, 15, 30, 45 and 60   10/06/2023  \n",
       "3                                10, 20, 30, and 45    01/03/2007  \n",
       "4                               5, 10, 15, 30 and 45   01/03/2007  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset from CSV file or URL\n",
    "df = pd.read_csv(\"Dissolution Methods.csv\")\n",
    "\n",
    "# Quick check to view the data\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb73f5a",
   "metadata": {},
   "source": [
    "Simulating the dataset (if dataset if not available). (OPTIONAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56078b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Simulating dissolution test metrics for 200 batches\n",
    "# np.random.seed(42)\n",
    "# fast_group = np.random.normal(\n",
    "#     loc=90, scale=5, size=(100, 3))  # high % dissolved\n",
    "# slow_group = np.random.normal(\n",
    "#     loc=60, scale=5, size=(100, 3))  # lower % dissolved\n",
    "# synthetic_data = np.vstack([fast_group, slow_group])\n",
    "\n",
    "# df = pd.DataFrame(synthetic_data, columns=[\n",
    "#                   \"% Dissolved @ 5min\", \"% Dissolved @ 10min\", \"% Dissolved @ 15min\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9532bf3",
   "metadata": {},
   "source": [
    "### 3. Data Cleaning & Preprocessing\n",
    "\n",
    "Preparing the dataset for use within the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9701d62e",
   "metadata": {},
   "source": [
    "#### 3.1. Data Cleaning\n",
    "\n",
    "Ensuring numerical features are clean and scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a251aec4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "at least one array or dtype is required",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Scale features for GMM\u001b[39;00m\n\u001b[32m      5\u001b[39m scaler = StandardScaler()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m X_scaled = scaler.fit_transform(numeric_df)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/PyScripts/dissolution_stability_ml_gmm_project/env/lib/python3.13/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = f(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs)\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/PyScripts/dissolution_stability_ml_gmm_project/env/lib/python3.13/site-packages/sklearn/base.py:894\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    879\u001b[39m         warnings.warn(\n\u001b[32m    880\u001b[39m             (\n\u001b[32m    881\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) has a `transform`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    889\u001b[39m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    890\u001b[39m         )\n\u001b[32m    892\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    893\u001b[39m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, **fit_params).transform(X)\n\u001b[32m    895\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    896\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    897\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/PyScripts/dissolution_stability_ml_gmm_project/env/lib/python3.13/site-packages/sklearn/preprocessing/_data.py:907\u001b[39m, in \u001b[36mStandardScaler.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    905\u001b[39m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[32m    906\u001b[39m \u001b[38;5;28mself\u001b[39m._reset()\n\u001b[32m--> \u001b[39m\u001b[32m907\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.partial_fit(X, y, sample_weight)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/PyScripts/dissolution_stability_ml_gmm_project/env/lib/python3.13/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/PyScripts/dissolution_stability_ml_gmm_project/env/lib/python3.13/site-packages/sklearn/preprocessing/_data.py:943\u001b[39m, in \u001b[36mStandardScaler.partial_fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    911\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[32m    912\u001b[39m \n\u001b[32m    913\u001b[39m \u001b[33;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    940\u001b[39m \u001b[33;03m    Fitted scaler.\u001b[39;00m\n\u001b[32m    941\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    942\u001b[39m first_call = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mn_samples_seen_\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m X = validate_data(\n\u001b[32m    944\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    945\u001b[39m     X,\n\u001b[32m    946\u001b[39m     accept_sparse=(\u001b[33m\"\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcsc\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    947\u001b[39m     dtype=FLOAT_DTYPES,\n\u001b[32m    948\u001b[39m     ensure_all_finite=\u001b[33m\"\u001b[39m\u001b[33mallow-nan\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    949\u001b[39m     reset=first_call,\n\u001b[32m    950\u001b[39m )\n\u001b[32m    951\u001b[39m n_features = X.shape[\u001b[32m1\u001b[39m]\n\u001b[32m    953\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/PyScripts/dissolution_stability_ml_gmm_project/env/lib/python3.13/site-packages/sklearn/utils/validation.py:2954\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2952\u001b[39m         out = X, y\n\u001b[32m   2953\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2954\u001b[39m     out = check_array(X, input_name=\u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m, **check_params)\n\u001b[32m   2955\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2956\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/PyScripts/dissolution_stability_ml_gmm_project/env/lib/python3.13/site-packages/sklearn/utils/validation.py:929\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m    925\u001b[39m pandas_requires_conversion = \u001b[38;5;28many\u001b[39m(\n\u001b[32m    926\u001b[39m     _pandas_dtype_needs_early_conversion(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dtypes_orig\n\u001b[32m    927\u001b[39m )\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype_iter, np.dtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype_iter \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[32m--> \u001b[39m\u001b[32m929\u001b[39m     dtype_orig = np.result_type(*dtypes_orig)\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m pandas_requires_conversion \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(d == \u001b[38;5;28mobject\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[32m    931\u001b[39m     \u001b[38;5;66;03m# Force object if any of the dtypes is an object\u001b[39;00m\n\u001b[32m    932\u001b[39m     dtype_orig = \u001b[38;5;28mobject\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: at least one array or dtype is required"
     ]
    }
   ],
   "source": [
    "# Drop non-numeric columns if needed\n",
    "numeric_df = df.select_dtypes(include=[np.number]).dropna()\n",
    "\n",
    "# Scale features for GMM\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(numeric_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a559d59",
   "metadata": {},
   "source": [
    "#### 3.2. Preprocessing\n",
    "\n",
    "In this case, all of the columns except the target column are going to be used to predict the targert column.\n",
    "\n",
    "In other words, using a patient's medical and demographic data to predict whether or not they have heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbfeb707",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'heart_disease' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create X (all the feature columns)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m X = heart_disease.drop(\u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m, axis=\u001b[32m1\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Create y (the target column)\u001b[39;00m\n\u001b[32m      5\u001b[39m y = heart_disease[\u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'heart_disease' is not defined"
     ]
    }
   ],
   "source": [
    "# Create X (all the feature columns)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "\n",
    "# Create y (the target column)\n",
    "y = heart_disease[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f749a0d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Split the data into training and test sets\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m X_train, X_test, y_train, y_test = train_test_split(X, y)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# View the data shapes\u001b[39;00m\n\u001b[32m      7\u001b[39m X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# View the data shapes\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb8999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
